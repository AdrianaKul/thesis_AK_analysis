{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T19:24:23.981874Z",
     "start_time": "2024-08-30T19:24:22.615380Z"
    }
   },
   "outputs": [],
   "source": [
    "# import settings and functions\n",
    "%run ./../../imports.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What mesh?\n",
    "\n",
    "Copy your choice to the next cell\n",
    "\n",
    "for SquareTop:\n",
    "```\n",
    "analytical_solution_tag = \"-ana_square_top\"\n",
    "generate_config = generateConfig_squareTop\n",
    "generate_mesh = generateMesh_squareTop\n",
    "```\n",
    "\n",
    "for SquareSinCos:\n",
    "```\n",
    "analytical_solution_tag = \"-ana_square_sincos\"\n",
    "generate_config = generateConfig_squareSinCos\n",
    "generate_mesh = generateMesh_squareSinCos\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T19:24:23.988792Z",
     "start_time": "2024-08-30T19:24:23.985264Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change according to instruction above\n",
    "analytical_solution_tag = \"-ana_mexi_hat\"\n",
    "generate_config = generateConfig_squareMexiHat\n",
    "generate_mesh = generateMesh_squareMexiHat\n",
    "\n",
    "# analytical_solution_tag = \"-ana_square_top\"\n",
    "# generate_config = generateConfig_squareTop\n",
    "# generate_mesh = generateMesh_squareTop\n",
    "\n",
    "# analytical_solution_tag = \"-ana_square_sincos\"\n",
    "# generate_config = generateConfig_squareSinCos\n",
    "# generate_mesh = generateMesh_squareSinCos\n",
    "\n",
    "# analytical_solution_tag = \"-ana_L_shape\"\n",
    "# generate_config = generateConfig_Lshape\n",
    "# generate_mesh = generateMesh_Lshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T19:24:24.003410Z",
     "start_time": "2024-08-30T19:24:23.991134Z"
    }
   },
   "outputs": [],
   "source": [
    "# prefix = \"c5_hat_missing_\"\n",
    "\n",
    "# which executable?\n",
    "\n",
    "exe = data_driven_diffusion_snes\n",
    "sumanalys = \"sumanalys.csv\"\n",
    "ana_name = \"ana_square_mexi_mixed_order\"\n",
    "\n",
    "ana_compare_exe = [data_driven_diffusion_snes, classic_diffusion]\n",
    "ana_compare_name = [\"ana_square_mexi_dd\", \"ana_square_mexi_classic\"]\n",
    "# ana_compare_name = [\"ana_square_mexi_mixed\"]\n",
    "ana_compare_sum = [\"sumanalys.csv\", \"sumanalys.csv\", \"FEM_errors.csv\", \"sumanalys.csv\"]\n",
    "\n",
    "# Convergence analysis parameters\n",
    "order_list = [1, 2, 3] # approximation order p\n",
    "elem_size_list = [0.08, 0.04, 0.02] # element size h\n",
    "# elem_size_list = [0.1, 0.05, 0.025] # element size h\n",
    "# order_list = [2, 3] # approximation order p\n",
    "# elem_size_list = [1./3., 1./7., 1./13.] # element size h\n",
    "params.triangle_mesh = True\n",
    "params.nproc = 1 # number of processors\n",
    "jumps = \"\"\n",
    "if params.nproc == 1:\n",
    "    jumps = \"-get_jumps\"\n",
    "# jumps = \"-get_jumps\"\n",
    "\n",
    "run_test = True\n",
    "run_analysis = True\n",
    "\n",
    "# params.triangle_mesh = False\n",
    "\n",
    "run_test = False\n",
    "run_analysis = False\n",
    "\n",
    "# naming = [\"order\", \"gaussnum\", \"iterations\",\"volume\", \"datanum\",\"rmsPoiErr\", \"errorEstimator\",\n",
    "#           \"L2norm\", \"H1seminorm\",\"fluxErr\", \"orderRefinementCounter\", \"errorIndicatorGrad\", \"errorIndicatorDiv\", \"jumpL2\", \"jumpHdiv\", \"eleNum\"]\n",
    "naming = [\"order\", \"gaussnum\", \"iterations\",\"volume\", \"datanum\",\"rmsPoiErr\", \"errorEstimator\",\n",
    "          \"L2norm\", \"H1seminorm\",\"fluxErr\", \"orderRefinementCounter\"]\n",
    "\n",
    "error_name_list = [\"L2norm\", \"H1seminorm\", \"fluxErr\"]\n",
    "error_label_list = [(r'Global error $L^2$-norm'),\n",
    "               (r'Global error $H^1$-seminorm'), (r'Global Flux error')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T19:24:24.015453Z",
     "start_time": "2024-08-30T19:24:24.005749Z"
    }
   },
   "outputs": [],
   "source": [
    "params.conductivity = 1.0 # linear conductivity\n",
    "# params.element_size = elem_size_list[0] # element size in the regular mesh\n",
    "params.element_size = 0.05\n",
    "params.order = 2 # approximation order for displacements\n",
    "\n",
    "# params.triangle_mesh = False # use triangular mesh\n",
    "\n",
    "# Pre-processing parameters\n",
    "# params.mesh_file = \"square_mexi\"\n",
    "params.mesh_file = \"L_shape\"\n",
    "params.length_x = 1\n",
    "params.length_y = 1\n",
    "params.length_z = 0\n",
    "params.show_mesh = True\n",
    "\n",
    "\n",
    "# solution parameters\n",
    "params.log_file = \"log\" # log file name \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T19:24:24.137427Z",
     "start_time": "2024-08-30T19:24:24.017107Z"
    }
   },
   "outputs": [],
   "source": [
    "# start display for showing results\n",
    "display = Display(backend=\"xvfb\", visible=False, size=(1024, 768))\n",
    "display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T19:24:25.457946Z",
     "start_time": "2024-08-30T19:24:24.139221Z"
    }
   },
   "outputs": [],
   "source": [
    "# Testing mesh generation\n",
    "if run_test:\n",
    "    params.show_mesh = True\n",
    "    generate_config(params)\n",
    "    generate_mesh(params)\n",
    "\n",
    "# stop the display\n",
    "display.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T19:24:25.947113Z",
     "start_time": "2024-08-30T19:24:25.459526Z"
    }
   },
   "outputs": [],
   "source": [
    "params.part_file = params.mesh_file + \"_\" + str(params.nproc) + \"p.h5m\"\n",
    "!{mofem_part} -my_file {params.mesh_file + \".h5m\"} -my_nparts {params.nproc} -output_file {params.part_file} -dim 2 -adj_dim 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T19:24:26.441559Z",
     "start_time": "2024-08-30T19:24:25.949569Z"
    }
   },
   "outputs": [],
   "source": [
    "# recreate dataset\n",
    "recreate_dataset = True\n",
    "csv_name = \"dummy_tree\"\n",
    "\n",
    "dummy_noise = 0.1\n",
    "\n",
    "dummy_count = 10000\n",
    "\n",
    "if recreate_dataset:\n",
    "    !{create_csv_dataset} -output_file {csv_name}.csv -my_dummy_noise_q 0 -my_dummy_noise_k {dummy_noise} -my_dummy_k 1 -my_dummy_range_dp 9.0 -my_dummy_count {int(dummy_count)}\n",
    "\n",
    "    scal = np.genfromtxt('./scaling.in')\n",
    "    print(scal)\n",
    "\n",
    "data = pd.read_csv(csv_name+\".csv\", index_col=False)\n",
    "headers = []\n",
    "headers = data.columns.values\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T19:24:26.448061Z",
     "start_time": "2024-08-30T19:24:26.444148Z"
    }
   },
   "outputs": [],
   "source": [
    "noise_list = [0.0, 0.01, 0.02, 0.05, 0.1]\n",
    "# noise_list = [0.02, 0.05, 0.1]\n",
    "ana_name = \"noise_sincos_\"\n",
    "\n",
    "ana_name_list = []\n",
    "\n",
    "for noise in noise_list:\n",
    "    ana_name_list.append(ana_name + str(noise))\n",
    "    \n",
    "# dummy_count_list = [1e3, 1e4, 1e5, 1e6, 1e7]\n",
    "dummy_count_list = [1e3, 1e4, 1e5, 1e6]\n",
    "\n",
    "realisations = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-30T19:24:22.036Z"
    }
   },
   "outputs": [],
   "source": [
    "if run_analysis:\n",
    "    !rm sumanalys.csv # making sure the previous analysis doesn't affect this one\n",
    "\n",
    "    # loop over noise_lisgt and ana_name_list\n",
    "    for (noise_in, ana_csv_name) in zip(noise_list, ana_name_list):\n",
    "        for dummy_count in dummy_count_list:\n",
    "#             !{create_csv_dataset} -output_file {csv_name}.csv -my_dummy_noise_q 0 -my_dummy_noise_k {noise_in} -my_dummy_k 1 -my_dummy_range_dp 9.0 -my_dummy_count {int(dummy_count)}\n",
    "\n",
    "            for i in range(realisations):\n",
    "#                 recreate dataset for each realisation\n",
    "                !{create_csv_dataset} -output_file {csv_name}.csv -my_dummy_noise_q 0 -my_dummy_noise_k {noise_in} -my_dummy_k 1 -my_dummy_range_dp 9.0 -my_dummy_count {int(dummy_count)}\n",
    "#                 run analysis\n",
    "                !{exe} -file_name {params.part_file} -my_order {params.order} {analytical_solution_tag} -csv_tree_file {csv_name}.csv -write_long_error_file -rand_ini \n",
    "\n",
    "        !mv ./sumanalys.csv ./{ana_csv_name}.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-30T19:24:22.037Z"
    }
   },
   "outputs": [],
   "source": [
    "ana_df_list = []\n",
    "\n",
    "for ana_name in ana_name_list:\n",
    "    ana_df_list.append(pd.read_csv(f'{ana_name}.csv', header=None, names=naming,  index_col=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-30T19:24:22.038Z"
    }
   },
   "outputs": [],
   "source": [
    "print(ana_df_list[0].head())\n",
    "\n",
    "# print headers\n",
    "print(ana_df_list[0].columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-30T19:24:22.039Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_dd_ana(ana_df_list, noise_list, errorType='L2norm', grouping='mean', label = \"\", box_plots=0, yscale_log=False):\n",
    "    # plt.ioff()  # Turn off interactive plotting\n",
    "    first_point = 1\n",
    "    grouped_data_list = []\n",
    "    for a in range(0, len(ana_df_list)):\n",
    "\n",
    "        if grouping == 'mean':\n",
    "            grouped_data_list.append(ana_df_list[a].groupby(['datanum']).mean())\n",
    "            plot_title = 'Mean'\n",
    "        if grouping == 'std':\n",
    "            grouped_data_list.append(ana_df_list[a].groupby(['datanum']).std())\n",
    "            plot_title = 'Standard Deviation'\n",
    "        if grouping == 'var':\n",
    "            grouped_data_list.append(ana_df_list[a].groupby(['datanum']).var())\n",
    "            plot_title = 'Variance'\n",
    "        if grouping == 'median':\n",
    "            grouped_data_list.append(ana_df_list[a].groupby(['datanum']).median())\n",
    "            plot_title = 'Median'\n",
    "\n",
    "        if box_plots == 1:\n",
    "            fig = plt.figure()\n",
    "            ax1 = sns.boxplot(x=\"datanum\", y=ana_df_list[a][errorType], data=ana_df_list[a]).set_title(errorType + ', noise = ' + str(noise_list[a]))\n",
    "            if yscale_log == True:\n",
    "                plt.yscale('log')\n",
    "            plt.savefig('boxplot_' + errorType + '_noise_' + str(noise_list[a]) + '.png')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "    if box_plots == 1:\n",
    "        fig = plt.figure()\n",
    "        for a in range(0, len(ana_df_list)):\n",
    "            sns.boxplot(x=\"datanum\", y=ana_df_list[a][errorType], data=ana_df_list[a])\n",
    "        if yscale_log == True:\n",
    "            plt.yscale('log')\n",
    "        plt.savefig('boxplot_' + errorType + '.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    # print(grouped_data_list[0].index)\n",
    "    # print(grouped_data_list[0].head())\n",
    "    # print(grouped_data_list[0][\"L2norm\"][first_point:])\n",
    "\n",
    "    # how to get L2norm out?\n",
    "    # print(grouped_data_list[0][errorType])\n",
    "\n",
    "    fig = plt.figure()\n",
    "    for a in range(0, len(ana_df_list)):\n",
    "        # print(grouped_data_list[a].index)\n",
    "        # print(grouped_data_list[a][errorType])\n",
    "        # translate index and errorType to numpy arrays with float values\n",
    "        x = np.array(grouped_data_list[a].index).astype(float)\n",
    "        y = np.array(grouped_data_list[a][errorType]).astype(float)\n",
    "        print(x)\n",
    "        print(y)\n",
    "        print(noise_list[a])\n",
    "\n",
    "        plt.plot(x, y, '-x', label = 'noise = ' + str(noise_list[a]))\n",
    "    plt.xscale('log')\n",
    "    plt.legend(loc='best')\n",
    "    if label:        \n",
    "        plt.ylabel(label)\n",
    "    else:\n",
    "        plt.ylabel(errorType)\n",
    "    plt.xlabel(r'\\# data points')\n",
    "    plt.title(plot_title)\n",
    "    plt.grid(True)\n",
    "    if yscale_log == True:\n",
    "        plt.yscale('log')\n",
    "\n",
    "    plt.savefig(grouping + '_' + errorType + '.png')\n",
    "    plt.show()\n",
    "    # plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-30T19:24:22.040Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_dd_shaded_ana(ana_df_list, noise_list, errorType='L2norm', label=\"\", yscale_log=False):\n",
    "    fig = plt.figure()\n",
    "    plot_title = 'Mean with Standard Deviation'\n",
    "\n",
    "    for a in range(0, len(ana_df_list)):\n",
    "        # Group by 'datanum' and calculate mean and std\n",
    "        grouped_data = ana_df_list[a].groupby(['datanum']).agg([np.mean, np.std])\n",
    "        x = np.array(grouped_data.index).astype(float)\n",
    "        y_mean = np.array(grouped_data[(errorType, 'mean')]).astype(float)\n",
    "        y_std = np.array(grouped_data[(errorType, 'std')]).astype(float)\n",
    "\n",
    "        # Plot mean\n",
    "        plt.plot(x, y_mean, '-x', label='noise = ' + str(noise_list[a]))\n",
    "\n",
    "        # Shade the area for standard deviation\n",
    "        plt.fill_between(x, y_mean - y_std, y_mean + y_std, alpha=0.5)\n",
    "\n",
    "    plt.xscale('log')\n",
    "    if yscale_log:\n",
    "        plt.yscale('log')\n",
    "    # legend with fond size 10\n",
    "    plt.legend(loc='best', prop={'size': 10})\n",
    "    if label:\n",
    "        plt.ylabel(label)\n",
    "    else:\n",
    "        plt.ylabel(errorType)\n",
    "    plt.xlabel(r'\\# data points')\n",
    "    plt.title(plot_title)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(errorType + '.png')\n",
    "    plt.show()\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-30T19:24:22.041Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_dd_shaded_ana(ana_df_list, noise_list, errorType='L2norm', label=r'Global error $L^2$-norm', yscale_log=True)\n",
    "\n",
    "plot_dd_shaded_ana(ana_df_list, noise_list, errorType='H1seminorm', label=r'Global error $H^1$-seminorm', yscale_log=True)\n",
    "\n",
    "plot_dd_shaded_ana(ana_df_list, noise_list, errorType='fluxErr', label=r'Global Flux error', yscale_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-30T19:24:22.041Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# naming = [\"order\", \"gaussnum\", \"iterations\",\"volume\", \"datanum\",\"rmsPoiErr\", \"errorEstimator\",\n",
    "#           \"L2norm\", \"H1seminorm\",\"fluxErr\", \"orderRefinementCounter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-30T19:24:22.042Z"
    }
   },
   "outputs": [],
   "source": [
    "# mean\n",
    "plot_dd_ana(ana_df_list, noise_list, errorType='L2norm', grouping='mean', label = \"L2-norm\", box_plots=1, yscale_log=True)\n",
    "# # std\n",
    "# plot_dd_ana(ana_df_list, noise_list, errorType='L2norm', grouping='std', label = \"L2-norm\", box_plots=1, yscale_log=False)\n",
    "\n",
    "\n",
    "plot_dd_ana(ana_df_list, noise_list, errorType='H1seminorm', grouping='mean', label = \"H1-seminorm\", box_plots=1, yscale_log=True)\n",
    "\n",
    "plot_dd_ana(ana_df_list, noise_list, errorType='fluxErr', grouping='mean', label = \"Flux L2-norm\", box_plots=1, yscale_log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-30T19:24:22.043Z"
    }
   },
   "outputs": [],
   "source": [
    "# class MyAnalysis:\n",
    "#     def __init__(self):\n",
    "#         self.varName = 'unidentified'\n",
    "#         d1 = pd.DataFrame()\n",
    "#         d2 = pd.DataFrame()\n",
    "#         d3 = pd.DataFrame()\n",
    "#         d4 = pd.DataFrame()\n",
    "#         d5 = pd.DataFrame()\n",
    "#         d6 = pd.DataFrame()\n",
    "#         d7 = pd.DataFrame()\n",
    "#         d8 = pd.DataFrame()\n",
    "#         d9 = pd.DataFrame()\n",
    "#         self.variable = []\n",
    "#         self.csvNaming = []\n",
    "#         self.list = []\n",
    "#         self.data_list = [d1,d2,d3,d4,d5,d6,d7,d8,d9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-30T19:24:22.044Z"
    }
   },
   "outputs": [],
   "source": [
    "# noiseAna = MyAnalysis()\n",
    "\n",
    "# # list analysis name with desired changin variable\n",
    "# noiseAna.varName = 'noise'\n",
    "# # noiseAna.list.append(['AS_noiseAna00', 0])\n",
    "# # noiseAna.list.append(['AS_noiseAna0005', 0.005])\n",
    "# # noiseAna.list.append(['AS_noiseAna001', 0.01])\n",
    "# # noiseAna.list.append(['AS_noiseAna005', 0.05])\n",
    "# noiseAna.list.append(['AS_noiseAna01', 0.1])\n",
    "# # noiseAna.list.append(['AS_noiseAna02', 0.2])\n",
    "\n",
    "# # populate the required fields\n",
    "# for i in range(0,len(noiseAna.list)):\n",
    "#     noiseAna.csvNaming.append(noiseAna.list[i][0])\n",
    "#     noiseAna.variable.append(float(noiseAna.list[i][1]))\n",
    "\n",
    "# #  just a check\n",
    "# print('variable name: ' + noiseAna.varName)\n",
    "# print('naming: ' + str(noiseAna.csvNaming))\n",
    "# print('variables: ' + str(noiseAna.variable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-30T19:24:22.045Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(exe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-30T19:24:22.045Z"
    }
   },
   "outputs": [],
   "source": [
    "# if run_analysis:\n",
    "#     # comment changing variables\n",
    "#     # in_order = 2\n",
    "#     # in_k = -3\n",
    "#     # in_range = 4 # defined above\n",
    "#     # in_count = 10000\n",
    "#     # in_noise = 0\n",
    "    \n",
    "#     !rm sumanalys.csv # making sure the previous analysis doesn't affect this one\n",
    "\n",
    "#     for a in range(0,len(noiseAna.variable)):\n",
    "#         in_noise = noiseAna.variable[a]\n",
    "#         csvName = noiseAna.csvNaming[a] + '.csv'\n",
    "#         for i in range(3,5): # 10^1 number of points in the data set\n",
    "#             dummy_count = 10**(i)\n",
    "#             !{create_csv_dataset} -output_file {csv_name}.csv -my_dummy_noise_q 0 -my_dummy_noise_k {dummy_noise} -my_dummy_k 1 -my_dummy_range_dp 9.0 -my_dummy_count {int(dummy_count)}\n",
    "#             for j in range(1,30): # how many realisations\n",
    "#                 !{exe} -file_name {params.part_file} -my_order {params.order} {analytical_solution_tag} -csv_tree_file {csv_name}.csv -write_long_error_file -rand_ini\n",
    "#         !mv ./sumanalys.csv ./{csvName}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-30T19:24:22.046Z"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# print(\n",
    "#     \"Loading plot_data(analysis, errorType='rmsErr', grouping='mean', box_plots=0, first_point=0, fig_size=[6.4, 4.8], yscale_log=False, fond_size=15)\")\n",
    "\n",
    "# print(\"errorType: rmsErr, p_difference, justErr, rmsPoiErr, iterations \\ngrouping: mean, std, var \\nbox_plots: 1=yes, 0=no \\nyscale_log: False, True\")\n",
    "\n",
    "\n",
    "# def plot_dd_ana(analysis, errorType='L2norm', grouping='mean', box_plots=0, first_point=0, fig_size=[6.4, 4.8], yscale_log=False, fond_size=15):\n",
    "#     grouped_data = [None] * len(analysis.variable)\n",
    "#     y = [None] * len(analysis.variable)\n",
    "#     for a in range(0, len(analysis.variable)):\n",
    "\n",
    "#         if grouping == 'mean':  # taking averages\n",
    "#             grouped_data[a] = analysis.data_list[a].groupby(['datanum']).mean()\n",
    "#             plot_title = 'Mean'\n",
    "#         if grouping == 'std':  # taking standard deviation\n",
    "#             grouped_data[a] = analysis.data_list[a].groupby(['datanum']).std()\n",
    "#             plot_title = 'Standard Deviation' # check the terminology\n",
    "#         if grouping == 'var':  # taking standard deviation\n",
    "#             grouped_data[a] = analysis.data_list[a].groupby(['datanum']).var()\n",
    "#             plot_title = 'Variance'\n",
    "#         if grouping == 'median':  # taking standard deviation\n",
    "#             grouped_data[a] = analysis.data_list[a].groupby(\n",
    "#                 ['datanum']).median()\n",
    "#             plot_title = 'Median'\n",
    "\n",
    "#         if errorType == 'rmsPoiErr':\n",
    "#             y[a] = grouped_data[a].rmsPoiErr\n",
    "#             y_box = analysis.data_list[a].rmsPoiErr\n",
    "#             y_label = 'Point distance RMS error'\n",
    "#         # if errorType == 'rmsErrPerc':\n",
    "#         #     y[a] = grouped_data[a].rmsErrPerc\n",
    "#         #     y_box = analysis.data_list[a].rmsErrPerc\n",
    "#         #     y_label = 'Pressure RMS error [%]'\n",
    "#         if errorType == 'L2norm':\n",
    "#             y[a] = grouped_data[a].L2norm\n",
    "#             y_box = analysis.data_list[a].L2norm\n",
    "#             y_label = 'Temperature RMS error'\n",
    "#         # if errorType == 'justErr':\n",
    "#         #     y[a] = grouped_data[a].justErr\n",
    "#         #     y_box = analysis.data_list[a].justErr\n",
    "#         #     y_label = 'Accumulated pressure error'\n",
    "#         # if errorType == 'p_difference':\n",
    "#         #     y[a] = grouped_data[a].p_difference\n",
    "#         #     y_box = analysis.data_list[a].p_difference\n",
    "#         #     y_label = 'Accumulated pressure difference'\n",
    "#         if errorType == 'iterations':\n",
    "#             y[a] = grouped_data[a].iterations\n",
    "#             y_box = analysis.data_list[a].iterations\n",
    "#             y_label = '# iterations'\n",
    "\n",
    "#         if box_plots == 1:  # plotting box plots\n",
    "#             fig = plt.figure(figsize=fig_size)\n",
    "#             ax1 = sns.boxplot(x=\"datanum\", y=y_box, data=analysis.data_list[a]).set_title(\n",
    "#                 analysis.varName + ' = ' + str(analysis.variable[a]))\n",
    "#             plt.show()\n",
    "\n",
    "#     # fig = plt.figure(figsize=(9, 6))\n",
    "#     fig = plt.figure(figsize=fig_size)\n",
    "#     for a in range(0, len(analysis.variable)):\n",
    "#         plt.plot(grouped_data[a].index[first_point:], y[a][first_point:], '-x',\n",
    "#                  label=(analysis.varName + ' = ' + str(analysis.variable[a])))\n",
    "#         plt.xscale('log')\n",
    "#         plt.legend(loc='best')\n",
    "#         plt.ylabel(y_label, fontsize=fond_size)\n",
    "#         plt.xlabel(\"# data points\", fontsize=fond_size)\n",
    "#         plt.title(plot_title, fontsize=fond_size)\n",
    "#         plt.grid(True)\n",
    "#         if yscale_log == True:\n",
    "#             plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-30T19:24:22.047Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# import seaborn as sns\n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-30T19:24:22.048Z"
    }
   },
   "outputs": [],
   "source": [
    "# analysis = noiseAna\n",
    "# # move to after analysis was run\n",
    "# for a in range(0,len(analysis.variable)):\n",
    "#     analysis.data_list[a] = pd.read_csv(analysis.csvNaming[a]+'.csv', header=None, names=naming)\n",
    "\n",
    "# plot_dd_ana(analysis, 'L2norm', 'std', 1, fig_size = [6,4])\n",
    "# plot_dd_ana(analysis, 'L2norm', 'std', first_point = 2)\n",
    "# plot_dd_ana(analysis, 'L2norm', 'var', first_point = 2)\n",
    "\n",
    "# # box_ave(noiseAna, 'iterations')\n",
    "# # box_ave(noiseAna, 'rmsPoiErr')\n",
    "# # box_ave(noiseAna, 'rmsErr')\n",
    "# # box_ave(noiseAna, 'rmsErrPerc',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-30T19:24:22.048Z"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# print(\n",
    "#     \"Loading plot_data(analysis, errorType='rmsErr', grouping='mean', box_plots=0, first_point=0, fig_size=[6.4, 4.8], yscale_log=False, fond_size=15)\")\n",
    "\n",
    "# print(\"errorType: rmsErr, p_difference, justErr, rmsPoiErr, iterations \\ngrouping: mean, std, var \\nbox_plots: 1=yes, 0=no \\nyscale_log: False, True\")\n",
    "\n",
    "\n",
    "# def plot_dd_ana(analysis, errorType='L2norm', grouping='mean', box_plots=0, first_point=0, fig_size=[6.4, 4.8], yscale_log=False, fond_size=15):\n",
    "#     grouped_data = [None] * len(analysis.variable)\n",
    "#     y = [None] * len(analysis.variable)\n",
    "#     for a in range(0, len(analysis.variable)):\n",
    "\n",
    "#         if grouping == 'mean':  # taking averages\n",
    "#             grouped_data[a] = analysis.data_list[a].groupby(['datanum']).mean()\n",
    "#             plot_title = 'Mean'\n",
    "#         if grouping == 'std':  # taking standard deviation\n",
    "#             grouped_data[a] = analysis.data_list[a].groupby(['datanum']).std()\n",
    "#             plot_title = 'Standard Deviation' # check the terminology\n",
    "#         if grouping == 'var':  # taking standard deviation\n",
    "#             grouped_data[a] = analysis.data_list[a].groupby(['datanum']).var()\n",
    "#             plot_title = 'Variance'\n",
    "#         if grouping == 'median':  # taking standard deviation\n",
    "#             grouped_data[a] = analysis.data_list[a].groupby(\n",
    "#                 ['datanum']).median()\n",
    "#             plot_title = 'Median'\n",
    "\n",
    "#         if errorType == 'rmsPoiErr':\n",
    "#             y[a] = grouped_data[a].rmsPoiErr\n",
    "#             y_box = analysis.data_list[a].rmsPoiErr\n",
    "#             y_label = 'Point distance RMS error'\n",
    "#         # if errorType == 'rmsErrPerc':\n",
    "#         #     y[a] = grouped_data[a].rmsErrPerc\n",
    "#         #     y_box = analysis.data_list[a].rmsErrPerc\n",
    "#         #     y_label = 'Pressure RMS error [%]'\n",
    "#         if errorType == 'L2norm':\n",
    "#             y[a] = grouped_data[a].L2norm\n",
    "#             y_box = analysis.data_list[a].L2norm\n",
    "#             y_label = 'Temperature RMS error'\n",
    "#         # if errorType == 'justErr':\n",
    "#         #     y[a] = grouped_data[a].justErr\n",
    "#         #     y_box = analysis.data_list[a].justErr\n",
    "#         #     y_label = 'Accumulated pressure error'\n",
    "#         # if errorType == 'p_difference':\n",
    "#         #     y[a] = grouped_data[a].p_difference\n",
    "#         #     y_box = analysis.data_list[a].p_difference\n",
    "#         #     y_label = 'Accumulated pressure difference'\n",
    "#         if errorType == 'iterations':\n",
    "#             y[a] = grouped_data[a].iterations\n",
    "#             y_box = analysis.data_list[a].iterations\n",
    "#             y_label = '# iterations'\n",
    "\n",
    "#         if box_plots == 1:  # plotting box plots\n",
    "#             fig = plt.figure(figsize=fig_size)\n",
    "#             ax1 = sns.boxplot(x=\"datanum\", y=y_box, data=analysis.data_list[a]).set_title(\n",
    "#                 analysis.varName + ' = ' + str(analysis.variable[a]))\n",
    "#             plt.show()\n",
    "\n",
    "#     # fig = plt.figure(figsize=(9, 6))\n",
    "#     fig = plt.figure(figsize=fig_size)\n",
    "#     for a in range(0, len(analysis.variable)):\n",
    "#         plt.plot(grouped_data[a].index[first_point:], y[a][first_point:], '-x',\n",
    "#                  label=(analysis.varName + ' = ' + str(analysis.variable[a])))\n",
    "#         plt.xscale('log')\n",
    "#         plt.legend(loc='best')\n",
    "#         plt.ylabel(y_label, fontsize=fond_size)\n",
    "#         plt.xlabel(\"# data points\", fontsize=fond_size)\n",
    "#         plt.title(plot_title, fontsize=fond_size)\n",
    "#         plt.grid(True)\n",
    "#         if yscale_log == True:\n",
    "#             plt.yscale('log')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
