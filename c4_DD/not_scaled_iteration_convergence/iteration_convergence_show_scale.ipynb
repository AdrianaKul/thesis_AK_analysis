{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import settings and functions\n",
    "%run ./../../dataset_creation_imports.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What mesh?\n",
    "\n",
    "Copy your choice to the next cell\n",
    "\n",
    "for SquareTop:\n",
    "```\n",
    "analytical_solution_tag = \"-ana_square_top\"\n",
    "generate_config = generateConfig_squareTop\n",
    "generate_mesh = generateMesh_squareTop\n",
    "```\n",
    "\n",
    "for SquareSinCos:\n",
    "```\n",
    "analytical_solution_tag = \"-ana_square_sincos\"\n",
    "generate_config = generateConfig_squareSinCos\n",
    "generate_mesh = generateMesh_squareSinCos\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change according to instruction above\n",
    "analytical_solution_tag = \"-ana_square_sincos\"\n",
    "generate_config = generateConfig_squareSinCos\n",
    "generate_mesh = generateMesh_squareSinCos\n",
    "\n",
    "# analytical_solution_tag = \"-ana_L_shape\"\n",
    "# generate_config = generateConfig_Lshape\n",
    "# generate_mesh = generateMesh_Lshape\n",
    "\n",
    "# analytical_solution_tag = \"-ana_mexi_hat\"\n",
    "# generate_config = generateConfig_squareMexiHat\n",
    "# generate_mesh = generateMesh_squareMexiHat\n",
    "\n",
    "# analytical_solution_tag = \"-ana_square_top\"\n",
    "# generate_config = generateConfig_squareTop\n",
    "# generate_mesh = generateMesh_squareTop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exe = data_driven_diffusion_snes\n",
    "\n",
    "k_in = 0.1\n",
    "k_label = \"01\"\n",
    "\n",
    "# k_in = 1\n",
    "# k_label = \"1\"\n",
    "\n",
    "# k_in = 10\n",
    "# k_label = \"10\"\n",
    "\n",
    "prefix = \"scale_DD_\"+str(k_label)+\"_\"\n",
    "\n",
    "# exe = hdiv_data_driven_diffusion_snes\n",
    "# prefix = \"scale_hdiv_DD_\"+str(k_label)+\"_\"\n",
    "\n",
    "use_line = \"-use_line\"\n",
    "use_line = \"\"\n",
    "\n",
    "if use_line:\n",
    "    prefix += \"line_\"\n",
    "    print(prefix)\n",
    "\n",
    "# exe = hdiv_data_driven_diffusion_snes\n",
    "# prefix = \"DD_hdiv_\"\n",
    "\n",
    "how_many_values = [11, 101, 1001, 10001]\n",
    "# how_many_values = [11, 101, 1001]\n",
    "\n",
    "run_simulation = True\n",
    "run_line_simulation = True\n",
    "\n",
    "run_simulation = False\n",
    "run_line_simulation = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_many = 41\n",
    "#\n",
    "params.conductivity = 1.0 # linear conductivity\n",
    "params.element_size = 0.05 # element size in the regular mesh\n",
    "params.order = 2 # approximation order for displacements\n",
    "# Pre-processing parameters\n",
    "params.mesh_file = \"square_top\"\n",
    "params.length_x = 1\n",
    "params.length_y = 1\n",
    "\n",
    "params.nproc = 1 # number of processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start display for showing results\n",
    "display = Display(backend=\"xvfb\", visible=False, size=(1024, 768))\n",
    "display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing mesh generation\n",
    "\n",
    "params.show_mesh = True\n",
    "generate_config(params)\n",
    "generate_mesh(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"grid_data.csv\"\n",
    "make_grid_linear_dataset(8, how_many, dataset_name, k_in, plot_dataset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing running analysis\n",
    "!rm out_*\n",
    "\n",
    "# use_line = \"-use_line\"\n",
    "# use_line = \"\"\n",
    "\n",
    "# how_many = 1001\n",
    "make_grid_linear_dataset(8, how_many, dataset_name, k_in, plot_dataset=False)\n",
    "\n",
    "params.part_file = params.mesh_file + \"_\" + str(params.nproc) + \"p.h5m\"\n",
    "!{mofem_part} -my_file {params.mesh_file + \".h5m\"} -my_nparts {params.nproc} -output_file {params.part_file} -dim 2 -adj_dim 1\n",
    "!{exe} -file_name {params.part_file} -my_order {params.order} {analytical_solution_tag} -csv_tree_file {dataset_name} -write_long_error_file {use_line} -print_integ -scaling 0 -my_dummy_k {k_in}  -snes_max_it 5000\n",
    "# -use_line -snes_max_it 500\n",
    "\n",
    "out_to_vtk = !ls -c1 out_result_*h5m\n",
    "\n",
    "!convert.py {out_to_vtk[0]}\n",
    "!convert.py out_error_1000.h5m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_lims = False\n",
    "!convert.py out_error_1000.h5m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params.field_part = -1\n",
    "params.show_file = \"out_iteration_\"\n",
    "params.show_file = \"out_result_\"\n",
    "params.show_field = \"T\"\n",
    "# params.warp_factor = 0.4  # warp factor\n",
    "params.p_cmap = color_temperature\n",
    "params.show_edges = True\n",
    "params.p_save = prefix+str(how_many)+\"_T.pdf\"\n",
    "show_results(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.show_field = \"Q\"\n",
    "params.field_part = 1\n",
    "params.p_cmap = color_flux\n",
    "params.p_save = prefix+str(how_many)+\"_Qy.pdf\"\n",
    "show_results(params)\n",
    "params.p_save = \"\"\n",
    "params.field_part = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DD_DISTANCE_AVE\")\n",
    "params.show_file = \"out_error\"\n",
    "params.show_field = \"DD_DISTANCE_AVE\"\n",
    "params.show_edges = True\n",
    "params.p_cmap = 'Purples'\n",
    "params.p_save = prefix+str(how_many)+\"dis_ave.pdf\"\n",
    "show_results(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point_file = \"out_integ_pts_6\"\n",
    "# !rm {point_file + \".vtk\"}\n",
    "\n",
    "out_to_vtk = !ls -c1 out_integ_pts_*.h5m\n",
    "last_file=out_to_vtk[0]\n",
    "print(last_file)\n",
    "!convert.py {last_file} \n",
    "\n",
    "# !mbconvert {point_file + \".h5m\"} {point_file + \".vtk\"}\n",
    "\n",
    "params.show_file = \"out_integ_pts_\"\n",
    "params.show_field = \"GRAD(P)_STAR\"\n",
    "params.field_part = 1\n",
    "# params.warp_factor = 0.4  # warp factor\n",
    "params.show_edges = True\n",
    "# params.p_save = \"run_test_p.pdf\"\n",
    "show_resulting_points(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.show_field = \"T\"\n",
    "params.field_part = -1\n",
    "# params.warp_factor = 0.4  # warp factor\n",
    "# params.p_save = \"run_test_p.pdf\"\n",
    "show_resulting_points(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_point_fields(vtk_file, point_index, csv_file):\n",
    "    # Read the .vtk file\n",
    "    mesh = pv.read(vtk_file)\n",
    "\n",
    "    # Get the point\n",
    "    point = mesh.points[point_index]\n",
    "\n",
    "    # Get the fields (scalars) of the point\n",
    "    fields = mesh.point_data\n",
    "\n",
    "    # Prepare data for saving\n",
    "    data_to_save = {field: fields[field][point_index] for field in fields}\n",
    "\n",
    "    # Save the fields to a .csv file\n",
    "    with open(csv_file, 'w') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=data_to_save.keys())\n",
    "        writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyvista as pv\n",
    "\n",
    "!convert.py out_integ_pts_*\n",
    "\n",
    "def get_point_fields(directory, point_index):\n",
    "    # Get the list of .vtk files\n",
    "    vtk_files = sorted(glob.glob(f\"{directory}/out_integ_pts_*.vtk\"), key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "\n",
    "    # Initialize a DataFrame to store the fields\n",
    "    df = None\n",
    "\n",
    "    for vtk_file in vtk_files:\n",
    "        # Read the .vtk file\n",
    "        mesh = pv.read(vtk_file)\n",
    "\n",
    "        # Get the fields (scalars) of the point\n",
    "        fields = mesh.point_data\n",
    "\n",
    "        # Prepare data for saving\n",
    "        data_to_save = {}\n",
    "        for field in fields:\n",
    "            if np.isscalar(fields[field][point_index]):\n",
    "                # Scalar field\n",
    "                data_to_save[field] = fields[field][point_index]\n",
    "            elif len(fields[field][point_index].shape) == 1:\n",
    "                # Vector field\n",
    "                for i in range(fields[field][point_index].shape[0]):\n",
    "                    data_to_save[f\"{field}_{i}\"] = fields[field][point_index][i]\n",
    "\n",
    "        # Add the file number to the data\n",
    "        file_number = int(vtk_file.split('_')[-1].split('.')[0])\n",
    "        data_to_save['file_number'] = file_number\n",
    "\n",
    "        # Append the data to the DataFrame\n",
    "        if df is None:\n",
    "            df = pd.DataFrame([data_to_save])\n",
    "        else:\n",
    "            df = pd.concat([df, pd.DataFrame([data_to_save])], ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# plot_point_fields(\".\", 20)\n",
    "df_gauss_vlaues = get_point_fields(\".\", 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gauss_vlaues = get_point_fields(\".\", 3139)\n",
    "# df_gauss_vlaues = get_point_fields(\".\", 1557)\n",
    "print(df_gauss_vlaues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"grid_data.csv\"\n",
    "grid_data = pd.read_csv(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interleave the points from 'fields' and 'stars'\n",
    "x_values = np.ravel(np.column_stack((df_gauss_vlaues['GRAD(P)_0'], df_gauss_vlaues['GRAD(P)_STAR_0'])))\n",
    "y_values = np.ravel(np.column_stack((df_gauss_vlaues['Q_0'], df_gauss_vlaues['Q_STAR_0'])))\n",
    "\n",
    "\n",
    "# Calculate the differences between consecutive points\n",
    "dx = np.diff(x_values)\n",
    "dy = np.diff(y_values)\n",
    "\n",
    "# Calculate the length of each line segment\n",
    "lengths = np.hypot(dx, dy)\n",
    "\n",
    "plt.figure()\n",
    "# plt.scatter(grid_data['gradx'], grid_data['fluxx'], label='Material dataset', zorder=1, s=2)\n",
    "plt.scatter(df_gauss_vlaues['GRAD(P)_0'], df_gauss_vlaues['Q_0'], label='Field values', marker='x', zorder=1)\n",
    "plt.scatter(df_gauss_vlaues['GRAD(P)_STAR_0'], df_gauss_vlaues['Q_STAR_0'], label='Closest data point', marker='*', zorder=1, color='b')\n",
    "# plot last point with different marker\n",
    "plt.scatter(df_gauss_vlaues['GRAD(P)_0'].iloc[-1], df_gauss_vlaues['Q_0'].iloc[-1], label='Resulting point', marker='x', zorder=1)\n",
    "\n",
    "# Normalize the lengths to get widths\n",
    "widths = lengths / np.max(lengths) * 0.005  # adjust the factor as needed\n",
    "\n",
    "# Plot each arrow individually with its own width\n",
    "for i in range(len(x_values[:-1])):\n",
    "    plt.quiver(x_values[i], y_values[i], dx[i], dy[i], scale_units='xy', angles='xy', scale=1, color='black', width=widths[i], zorder=2)\n",
    "\n",
    "# plt.xlabel('Greadient')\n",
    "# plt.ylabel('Flux')\n",
    "plt.xlabel(label_gradient_g_x)\n",
    "plt.ylabel(label_flux_x)\n",
    "plt.axis('equal')  # Equal aspect ratio\n",
    "# plt.xlim(-2.5,-1)\n",
    "# plt.ylim(0,0.5)\n",
    "# plt.xlim(5.,5.2)\n",
    "# plt.ylim(-0.55,-0.45)\n",
    "ax = plt.gca()  # Define ax variable\n",
    "ax.grid(True, ls=':')  # Call ax.grid() method\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.savefig(prefix+'integration_journey_x.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interleave the points from 'fields' and 'stars'\n",
    "x_values = np.ravel(np.column_stack((df_gauss_vlaues['GRAD(P)_1'], df_gauss_vlaues['GRAD(P)_STAR_1'])))\n",
    "y_values = np.ravel(np.column_stack((df_gauss_vlaues['Q_1'], df_gauss_vlaues['Q_STAR_1'])))\n",
    "\n",
    "\n",
    "# Calculate the differences between consecutive points\n",
    "dx = np.diff(x_values)\n",
    "dy = np.diff(y_values)\n",
    "\n",
    "# Calculate the length of each line segment\n",
    "lengths = np.hypot(dx, dy)\n",
    "\n",
    "plt.figure()\n",
    "# plt.scatter(grid_data['grady'], grid_data['fluxy'], label='Material dataset', zorder=1, s=2)\n",
    "plt.scatter(df_gauss_vlaues['GRAD(P)_1'], df_gauss_vlaues['Q_1'], label='Field values', marker='x', zorder=1)\n",
    "plt.scatter(df_gauss_vlaues['GRAD(P)_STAR_1'], df_gauss_vlaues['Q_STAR_1'], label='Closest data point', marker='*', zorder=1, color='b')\n",
    "# plot last point with different marker\n",
    "plt.scatter(df_gauss_vlaues['GRAD(P)_1'].iloc[-1], df_gauss_vlaues['Q_1'].iloc[-1], label='Resulting point', marker='x', zorder=1)\n",
    "\n",
    "# Normalize the lengths to get widths\n",
    "widths = lengths / np.max(lengths) * 0.005  # adjust the factor as needed\n",
    "\n",
    "# Plot each arrow individually with its own width\n",
    "for i in range(len(x_values[:-1])):\n",
    "    plt.quiver(x_values[i], y_values[i], dx[i], dy[i], scale_units='xy', angles='xy', scale=1, color='black', width=widths[i], zorder=2)\n",
    "\n",
    "# plt.xlabel('Greadient')\n",
    "# plt.ylabel('Flux')\n",
    "plt.xlabel(label_gradient_g_y)\n",
    "plt.ylabel(label_flux_y)\n",
    "plt.axis('equal')  # Equal aspect ratio\n",
    "# plt.xlim(-0.5,8)\n",
    "# plt.ylim(-8,0.5)\n",
    "ax = plt.gca()  # Define ax variable\n",
    "ax.grid(True, ls=':')  # Call ax.grid() method\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.savefig(prefix+'integration_journey_y.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('errors_long_file.csv', header=0,  index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(data['rmsErr_long_file'], label=r'Temperature error')\n",
    "# ax.plot(data[' rmsGradErr_long_file'], label=r'Gradient error')\n",
    "# ax.plot(data[' rmsFluxErr_long_file'], label=r'Flux error')\n",
    "# ax.plot(data[' rmsPointDistErr_long_file'], label=r'Point distance', ls='--', color='black', marker='o')\n",
    "# ax.set_yscale('log')\n",
    "# ax.grid(True, ls=':')\n",
    "# ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm out*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
