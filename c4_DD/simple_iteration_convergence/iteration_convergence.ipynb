{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import settings and functions\n",
    "%run ./../../dataset_creation_imports.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What mesh?\n",
    "\n",
    "Copy your choice to the next cell\n",
    "\n",
    "for SquareTop:\n",
    "```\n",
    "analytical_solution_tag = \"-ana_square_top\"\n",
    "generate_config = generateConfig_squareTop\n",
    "generate_mesh = generateMesh_squareTop\n",
    "```\n",
    "\n",
    "for SquareSinCos:\n",
    "```\n",
    "analytical_solution_tag = \"-ana_square_sincos\"\n",
    "generate_config = generateConfig_squareSinCos\n",
    "generate_mesh = generateMesh_squareSinCos\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change according to instruction above\n",
    "analytical_solution_tag = \"-ana_square_sincos\"\n",
    "generate_config = generateConfig_squareSinCos\n",
    "generate_mesh = generateMesh_squareSinCos\n",
    "\n",
    "# analytical_solution_tag = \"-ana_L_shape\"\n",
    "# generate_config = generateConfig_Lshape\n",
    "# generate_mesh = generateMesh_Lshape\n",
    "\n",
    "# analytical_solution_tag = \"-ana_mexi_hat\"\n",
    "# generate_config = generateConfig_squareMexiHat\n",
    "# generate_mesh = generateMesh_squareMexiHat\n",
    "\n",
    "# analytical_solution_tag = \"-ana_square_top\"\n",
    "# generate_config = generateConfig_squareTop\n",
    "# generate_mesh = generateMesh_squareTop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_many = 41\n",
    "#\n",
    "params.conductivity = 1.0 # linear conductivity\n",
    "params.element_size = 0.05 # element size in the regular mesh\n",
    "params.order = 2 # approximation order for displacements\n",
    "# Pre-processing parameters\n",
    "params.mesh_file = \"square_top\"\n",
    "params.length_x = 1\n",
    "params.length_y = 1\n",
    "\n",
    "params.nproc = 1 # number of processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start display for showing results\n",
    "display = Display(backend=\"xvfb\", visible=False, size=(1024, 768))\n",
    "display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing mesh generation\n",
    "\n",
    "params.show_mesh = True\n",
    "generate_config(params)\n",
    "generate_mesh(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"grid_data.csv\"\n",
    "make_grid_linear_dataset(8, how_many, dataset_name, plot_dataset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing running analysis\n",
    "!rm out_*\n",
    "\n",
    "use_line = \"-use_line\"\n",
    "use_line = \"\"\n",
    "\n",
    "how_many = 41\n",
    "make_grid_linear_dataset(8, how_many, dataset_name, plot_dataset=False)\n",
    "\n",
    "params.part_file = params.mesh_file + \"_\" + str(params.nproc) + \"p.h5m\"\n",
    "!{mofem_part} -my_file {params.mesh_file + \".h5m\"} -my_nparts {params.nproc} -output_file {params.part_file} -dim 2 -adj_dim 1\n",
    "!{data_driven_diffusion_snes} -file_name {params.part_file} -my_order {params.order} {analytical_solution_tag} -csv_tree_file {dataset_name} -write_long_error_file {use_line} -print_integ\n",
    "# data_driven_diffusion\n",
    "# hdiv_data_driven_diffusion\n",
    "\n",
    "out_to_vtk = !ls -c1 out_result_*h5m\n",
    "\n",
    "!convert.py {out_to_vtk[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params.show_file = \"out_iteration_\"\n",
    "params.show_file = \"out_result_\"\n",
    "params.show_field = \"T\"\n",
    "# params.warp_factor = 0.4  # warp factor\n",
    "params.show_edges = True\n",
    "# params.p_save = \"run_test_p.pdf\"\n",
    "show_results(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.show_field = \"Q\"\n",
    "params.field_part = 1\n",
    "show_results(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_file = \"out_integ_pts_6\"\n",
    "\n",
    "!mbconvert {point_file + \".h5m\"} {point_file + \".vtk\"}\n",
    "\n",
    "params.show_file = \"out_integ_pts_\"\n",
    "params.show_field = \"GRAD(P)_STAR\"\n",
    "params.field_part = 1\n",
    "# params.warp_factor = 0.4  # warp factor\n",
    "params.show_edges = True\n",
    "# params.p_save = \"run_test_p.pdf\"\n",
    "show_resulting_points(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.show_field = \"T\"\n",
    "# params.warp_factor = 0.4  # warp factor\n",
    "# params.p_save = \"run_test_p.pdf\"\n",
    "show_resulting_points(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_point_fields(vtk_file, point_index, csv_file):\n",
    "    # Read the .vtk file\n",
    "    mesh = pv.read(vtk_file)\n",
    "\n",
    "    # Get the point\n",
    "    point = mesh.points[point_index]\n",
    "\n",
    "    # Get the fields (scalars) of the point\n",
    "    fields = mesh.point_data\n",
    "\n",
    "    # Prepare data for saving\n",
    "    data_to_save = {field: fields[field][point_index] for field in fields}\n",
    "\n",
    "    # Save the fields to a .csv file\n",
    "    with open(csv_file, 'w') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=data_to_save.keys())\n",
    "        writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# point_file = \"out_integ_pts_6\"\n",
    "\n",
    "# !mbconvert {point_file + \".h5m\"} {point_file + \".vtk\"}\n",
    "# save_point_fields(point_file+\".vtk\", 0, \"point_fields.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyvista as pv\n",
    "\n",
    "!convert.py out_integ_pts_*\n",
    "\n",
    "def get_point_fields(directory, point_index):\n",
    "    # Get the list of .vtk files\n",
    "    vtk_files = sorted(glob.glob(f\"{directory}/out_integ_pts_*.vtk\"))\n",
    "\n",
    "    # Initialize a DataFrame to store the fields\n",
    "    df = None\n",
    "\n",
    "    for vtk_file in vtk_files:\n",
    "        # Read the .vtk file\n",
    "        mesh = pv.read(vtk_file)\n",
    "\n",
    "        # Get the fields (scalars) of the point\n",
    "        fields = mesh.point_data\n",
    "\n",
    "        # Prepare data for saving\n",
    "        data_to_save = {}\n",
    "        for field in fields:\n",
    "            if np.isscalar(fields[field][point_index]):\n",
    "                # Scalar field\n",
    "                data_to_save[field] = fields[field][point_index]\n",
    "            elif len(fields[field][point_index].shape) == 1:\n",
    "                # Vector field\n",
    "                for i in range(fields[field][point_index].shape[0]):\n",
    "                    data_to_save[f\"{field}_{i}\"] = fields[field][point_index][i]\n",
    "\n",
    "        # Add the file number to the data\n",
    "        file_number = int(vtk_file.split('_')[-1].split('.')[0])\n",
    "        data_to_save['file_number'] = file_number\n",
    "\n",
    "        # Append the data to the DataFrame\n",
    "        if df is None:\n",
    "            df = pd.DataFrame([data_to_save])\n",
    "        else:\n",
    "            df = pd.concat([df, pd.DataFrame([data_to_save])], ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# plot_point_fields(\".\", 20)\n",
    "df_gauss_vlaues = get_point_fields(\".\", 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_gauss_vlaues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"grid_data.csv\"\n",
    "grid_data = pd.read_csv(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interleave the points from 'fields' and 'stars'\n",
    "x_values = np.ravel(np.column_stack((df_gauss_vlaues['GRAD(P)_0'], df_gauss_vlaues['GRAD(P)_STAR_0'])))\n",
    "y_values = np.ravel(np.column_stack((df_gauss_vlaues['Q_0'], df_gauss_vlaues['Q_STAR_0'])))\n",
    "\n",
    "\n",
    "# Calculate the differences between consecutive points\n",
    "dx = np.diff(x_values)\n",
    "dy = np.diff(y_values)\n",
    "\n",
    "# Calculate the length of each line segment\n",
    "lengths = np.hypot(dx, dy)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(grid_data['gradx'], grid_data['fluxx'], label='Material dataset', zorder=1, s=2)\n",
    "plt.scatter(df_gauss_vlaues['GRAD(P)_0'], df_gauss_vlaues['Q_0'], label='Field values', marker='x', zorder=1)\n",
    "plt.scatter(df_gauss_vlaues['GRAD(P)_STAR_0'], df_gauss_vlaues['Q_STAR_0'], label='Closest data point', marker='*', zorder=1, color='b')\n",
    "\n",
    "# Normalize the lengths to get widths\n",
    "widths = lengths / np.max(lengths) * 0.005  # adjust the factor as needed\n",
    "\n",
    "# Plot each arrow individually with its own width\n",
    "for i in range(len(x_values[:-1])):\n",
    "    plt.quiver(x_values[i], y_values[i], dx[i], dy[i], scale_units='xy', angles='xy', scale=1, color='black', width=widths[i], zorder=2)\n",
    "\n",
    "# plt.xlabel('Greadient')\n",
    "# plt.ylabel('Flux')\n",
    "plt.xlabel(r'Temperature gradient')\n",
    "plt.ylabel(r'Heat flux')\n",
    "# plt.xlim(-0.5,8)\n",
    "# plt.ylim(-8,0.5)\n",
    "ax = plt.gca()  # Define ax variable\n",
    "ax.grid(True, ls=':')  # Call ax.grid() method\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('integration_journey.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('errors_long_file.csv', header=0,  index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(data['rmsErr_long_file'], label=r'Temperature error')\n",
    "ax.plot(data[' rmsGradErr_long_file'], label=r'Gradient error')\n",
    "ax.plot(data[' rmsFluxErr_long_file'], label=r'Flux error')\n",
    "ax.plot(data[' rmsPointDistErr_long_file'], label=r'Point distance', ls='--', color='black', marker='o')\n",
    "ax.set_yscale('log')\n",
    "ax.grid(True, ls=':')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot with line and with dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_error_file = \"errors_long_file.csv\"\n",
    "\n",
    "line_errors = \"line_errors.csv\"\n",
    "data_errors = \"data_errors.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_line = \"-use_line\"\n",
    "use_line = \"\"\n",
    "\n",
    "how_many = 101\n",
    "make_grid_linear_dataset(8, how_many, dataset_name, plot_dataset=False)\n",
    "\n",
    "params.part_file = params.mesh_file + \"_\" + str(params.nproc) + \"p.h5m\"\n",
    "!{mofem_part} -my_file {params.mesh_file + \".h5m\"} -my_nparts {params.nproc} -output_file {params.part_file} -dim 2 -adj_dim 1\n",
    "# !{classic_diffusion} -file_name {params.part_file} -my_order {params.order} {analytical_solution_tag}\n",
    "!{data_driven_diffusion_snes} -file_name {params.part_file} -my_order {params.order} {analytical_solution_tag} -csv_tree_file {dataset_name} -write_long_error_file {use_line}\n",
    "\n",
    "!mv {main_error_file} {data_errors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_line = \"-use_line\"\n",
    "\n",
    "# params.part_file = params.mesh_file + \"_\" + str(params.nproc) + \"p.h5m\"\n",
    "# !{mofem_part} -my_file {params.mesh_file + \".h5m\"} -my_nparts {params.nproc} -output_file {params.part_file} -dim 2 -adj_dim 1\n",
    "# # !{classic_diffusion} -file_name {params.part_file} -my_order {params.order} {analytical_solution_tag}\n",
    "# !{data_driven_diffusion_snes} -file_name {params.part_file} -my_order {params.order} {analytical_solution_tag} -csv_tree_file {dataset_name} -write_long_error_file {use_line}\n",
    "\n",
    "# !mv {main_error_file} {line_errors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_pd = pd.read_csv(line_errors, header=0,  index_col=False)\n",
    "data_pd = pd.read_csv(data_errors, header=0,  index_col=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(data_pd['rmsErr_long_file'], label=r'Temperature error')\n",
    "ax.plot(data_pd[' rmsGradErr_long_file'], label=r'Gradient error')\n",
    "ax.plot(data_pd[' rmsFluxErr_long_file'], label=r'Flux error')\n",
    "ax.plot(data_pd[' rmsPointDistErr_long_file'], label=r'Point distance', ls='--', color='black', marker='o')\n",
    "ax.set_ylabel(r'Global RMS error')\n",
    "ax.set_xlabel(r'Iteration')\n",
    "ax.set_yscale('log')\n",
    "ax.grid(True, ls=':')\n",
    "y_range = ax.get_ylim()\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"DD_small_data_errors_with_iterations.pdf\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(line_pd['rmsErr_long_file'], label=r'Temperature error')\n",
    "ax.plot(line_pd[' rmsGradErr_long_file'], label=r'Gradient error')\n",
    "ax.plot(line_pd[' rmsFluxErr_long_file'], label=r'Flux error')\n",
    "ax.plot(line_pd[' rmsPointDistErr_long_file'], label=r'Point distance', ls='--', color='black', marker='o')\n",
    "ax.set_ylabel(r'Global RMS error')\n",
    "ax.set_xlabel(r'Iteration')\n",
    "ax.set_yscale('log')\n",
    "ax.grid(True, ls=':')\n",
    "ax.legend()\n",
    "ax.set_ylim(y_range)\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"DD_line_errors_with_iterations.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
