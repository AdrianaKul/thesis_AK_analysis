{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T18:06:05.250997Z",
     "start_time": "2024-02-04T18:06:04.464573Z"
    }
   },
   "outputs": [],
   "source": [
    "# import settings and functions\n",
    "%run ./../../imports.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What mesh?\n",
    "\n",
    "Copy your choice to the next cell\n",
    "\n",
    "for SquareTop:\n",
    "```\n",
    "analytical_solution_tag = \"-ana_square_top\"\n",
    "generate_config = generateConfig_squareTop\n",
    "generate_mesh = generateMesh_squareTop\n",
    "```\n",
    "\n",
    "for SquareSinCos:\n",
    "```\n",
    "analytical_solution_tag = \"-ana_square_sincos\"\n",
    "generate_config = generateConfig_squareSinCos\n",
    "generate_mesh = generateMesh_squareSinCos\n",
    "```\n",
    "\n",
    "for MexiHat\n",
    "```\n",
    "analytical_solution_tag = \"-ana_mexi_hat\"\n",
    "generate_config = generateConfig_squareMexiHat\n",
    "generate_mesh = generateMesh_squareMexiHat\n",
    "```\n",
    "\n",
    "for Lshape\n",
    "```\n",
    "analytical_solution_tag = \"-ana_L_shape\"\n",
    "generate_config = generateConfig_Lshape\n",
    "generate_mesh = generateMesh_Lshape\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change according to instruction above\n",
    "analytical_solution_tag = \"\"\n",
    "generate_config = generateConfig_Lshape\n",
    "generate_mesh = generateMesh_Lshape\n",
    "\n",
    "# analytical_solution_tag = \"-ana_mexi_hat\"\n",
    "# generate_config = generateConfig_squareMexiHat\n",
    "# generate_mesh = generateMesh_squareMexiHat\n",
    "\n",
    "# analytical_solution_tag = \"-ana_square_top\"\n",
    "# generate_config = generateConfig_squareTop\n",
    "# generate_mesh = generateMesh_squareTop\n",
    "\n",
    "# analytical_solution_tag = \"-ana_square_sincos\"\n",
    "# generate_config = generateConfig_squareSinCos\n",
    "# generate_mesh = generateMesh_squareSinCos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which executable?\n",
    "\n",
    "exe = hdiv_data_driven_diffusion_snes\n",
    "sumanalys = \"sumanalys.csv\"\n",
    "ana_name = \"ana_DD_brick\"\n",
    "\n",
    "ana_compare_exe = [hdiv_data_driven_diffusion_snes]\n",
    "ana_compare_name = [\"ana_DD_brick_mixed\"]\n",
    "ana_compare_sum = [\"sumanalys.csv\"]\n",
    "\n",
    "# ana_compare_exe = [hdiv_diffusion, classic_diffusion]\n",
    "# ana_compare_name = [\"ana_brick_mixed\", \"ana_brick_classic\"]\n",
    "# ana_compare_sum = [\"sumanalys.csv\", \"FEM_errors.csv\"]\n",
    "\n",
    "# Convergence analysis parameters\n",
    "order_list = [1, 2, 3] # approximation order p\n",
    "elem_size_list = [0.5, 0.2, 0.1, 0.05, 0.02] # element size h\n",
    "# order_list = [1, 2, 3] # approximation order p\n",
    "# elem_size_list = [0.5, 0.2, 0.1, 0.05] # element size h\n",
    "params.triangle_mesh = True\n",
    "params.nproc = 1 # number of processors\n",
    "jumps = \"\"\n",
    "if params.nproc == 1:\n",
    "    jumps = \"-get_jumps\"\n",
    "# jumps = \"-get_jumps\"\n",
    "\n",
    "run_test = True\n",
    "run_analysis = True\n",
    "run_refinement_analysis = True\n",
    "run_refinement_mesh_analysis = True\n",
    "run_refinement_hp_analysis = True\n",
    "run_monte_carlo = True\n",
    "\n",
    "# run_test = False\n",
    "run_analysis = False\n",
    "run_refinement_analysis = False\n",
    "run_refinement_mesh_analysis = False\n",
    "# run_refinement_hp_analysis = False\n",
    "# run_monte_carlo = False\n",
    "\n",
    "monte = \"\"\n",
    "if run_monte_carlo:\n",
    "    monte = \"-monte_carlo 100 -skip_vtk 1 -monte_patch_number 2\"\n",
    "\n",
    "naming = [\"order\", \"gaussnum\", \"iterations\",\"volume\", \"datanum\",\"rmsPoiErr\", \"errorEstimator\",\n",
    "          \"L2norm\", \"H1seminorm\",\"fluxErr\", \"orderRefinementCounter\", \"errorIndicatorGrad\", \"errorIndicatorDiv\", \"jumpL2\", \"jumpHdiv\", \"eleNum\"]\n",
    "# naming = [\"order\", \"gaussnum\", \"iterations\",\"volume\", \"datanum\",\"rmsPoiErr\", \"errorEstimator\",\n",
    "#           \"L2norm\", \"H1seminorm\",\"fluxErr\", \"orderRefinementCounter\"]\n",
    "\n",
    "error_name_list = [\"L2norm\", \"H1seminorm\", \"fluxErr\"]\n",
    "error_label_list = [(r'Global error $L^2$-norm'),\n",
    "               (r'Global error $H^1$-seminorm'), (r'Global Flux error')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T18:06:05.254997Z",
     "start_time": "2024-02-04T18:06:05.252603Z"
    }
   },
   "outputs": [],
   "source": [
    "params.conductivity = 1.0 # linear conductivity\n",
    "params.element_size = 0.2 # element size in the regular mesh\n",
    "# params.element_size = elem_size_list[0] # element size in the regular mesh\n",
    "params.order = 1 # approximation order for displacements\n",
    "\n",
    "# params.triangle_mesh = False # use triangular mesh\n",
    "\n",
    "# Pre-processing parameters\n",
    "params.mesh_file = \"L_shape\"\n",
    "params.length_x = 1\n",
    "params.length_y = 1\n",
    "params.length_z = 0\n",
    "params.show_mesh = True\n",
    "\n",
    "\n",
    "# solution parameters\n",
    "params.log_file = \"log\" # log file name \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New brick meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.list_mesh_files = []\n",
    "params.element_sizes = []\n",
    "\n",
    "params.list_mesh_files.append(\"brick_20.cub\")\n",
    "params.element_sizes.append(5)\n",
    "\n",
    "params.list_mesh_files.append(\"brick_15.cub\")\n",
    "params.element_sizes.append(4)\n",
    "\n",
    "params.list_mesh_files.append(\"brick_10.cub\")\n",
    "params.element_sizes.append(3)\n",
    "\n",
    "params.list_mesh_files.append(\"brick_7.cub\")\n",
    "params.element_sizes.append(2)\n",
    "\n",
    "params.list_mesh_files.append(\"brick_6.cub\")\n",
    "params.element_sizes.append(1)\n",
    "\n",
    "params.list_mesh_files.append(\"brick_4.cub\")\n",
    "params.element_sizes.append(1)\n",
    "\n",
    "# which mesh to use\n",
    "input_number = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = params.element_sizes\n",
    "cub_names = params.list_mesh_files\n",
    "input_names = []\n",
    "for i in cub_names:\n",
    "    input_names.append(i[:-3]+\"h5m\")\n",
    "count = len(h)\n",
    "print(cub_names)\n",
    "print(input_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# partition the mesh\n",
    "for i in range(count):\n",
    "    # print(i)\n",
    "    !{tools_dir}/mofem_part -my_file {cub_names[i]} -output_file {input_names[i]} -my_nparts 1 -dim 2 -adj_dim 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T18:06:05.347658Z",
     "start_time": "2024-02-04T18:06:05.256058Z"
    }
   },
   "outputs": [],
   "source": [
    "# start display for showing results\n",
    "display = Display(backend=\"xvfb\", visible=False, size=(1024, 768))\n",
    "display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T18:06:06.528759Z",
     "start_time": "2024-02-04T18:06:05.372517Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Testing mesh generation\n",
    "# if run_test:\n",
    "#     params.show_mesh = True\n",
    "#     generate_config(params)\n",
    "#     generate_mesh(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -csv_tree_file data_VGQ_generated_scaled.csv\n",
    "\n",
    "params.csv_tree_file = \"data_VGQ_generated_scaled.csv\"\n",
    "\n",
    "params.csv_tree_file = \"data_VGQ_generated_scaled_trimmed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# a = 134.0\n",
    "# b = -0.1047\n",
    "# c = 3.719 *10**(-5)\n",
    "\n",
    "# nonlinear_a = a\n",
    "# nonlinear_b = b\n",
    "# nonlinear_c = c\n",
    "\n",
    "\n",
    "# if run_test:\n",
    "#     !rm out*\n",
    "#     params.part_file = input_names[0]\n",
    "#     !{diffusion_nonlinear_graphite} -file_name {params.part_file} -my_order 2 -nonlinear_a {nonlinear_a} -nonlinear_b {nonlinear_b} -nonlinear_c {nonlinear_c} -scaling 0\n",
    "#     !convert.py out*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing running analysis\n",
    "\n",
    "\n",
    "exe = hdiv_diffusion\n",
    "# exe = classic_diffusion\n",
    "# exe = data_driven_diffusion\n",
    "# # exe = data_driven_diffusion_snes\n",
    "exe = hdiv_data_driven_diffusion_snes\n",
    "# exe = hdiv_data_driven_diffusion\n",
    "\n",
    "if run_test:\n",
    "    !rm out*\n",
    "    params.part_file = input_names[3]\n",
    "    # params.mesh_file = cub_names[0]\n",
    "    # params.part_file = params.mesh_file + \"_\" + str(params.nproc) + \"p.h5m\"\n",
    "    # !{mofem_part} -my_file {params.mesh_file} -nparts {params.nproc} -output_file {params.part_file} -dim 2 -adj_dim 1\n",
    "    !mpirun -np {params.nproc} {exe} -file_name {params.part_file} -my_order {params.order} {analytical_solution_tag} {jumps} -csv_tree_file {params.csv_tree_file} -scaling 1 -snes_max_it 5 -refinement_style 3 -ref_iter_num 1 -refine_h_boundary_only\n",
    "    #  -use_line -data_dim 4 -my_dummy_k 100.0\n",
    "\n",
    "    !convert.py out*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_test:\n",
    "    params.show_file = \"out_iteration_\"\n",
    "    params.show_file = \"out_result_\"\n",
    "    params.show_field = \"T\"\n",
    "    # params.show_file = \"out_ori_result\"\n",
    "    # params.show_field = \"P_reference\"\n",
    "    # params.warp_factor = 0.4  # warp factor\n",
    "    params.show_edges = True\n",
    "    # params.p_save = \"run_test_p.pdf\"\n",
    "    show_results(params)\n",
    "    show_resulting_points(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if run_test:\n",
    "#     params.show_file = \"out_result\"\n",
    "#     params.show_field = \"T\"\n",
    "#     # params.show_file = \"out_ori_result\"\n",
    "#     # params.show_field = \"P_reference\"\n",
    "#     # params.warp_factor = 0.4  # warp factor\n",
    "#     # params.show_edges = True\n",
    "#     # params.p_save = \"run_test_p.pdf\"\n",
    "#     plot_gradients(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_test:\n",
    "    params.show_file = \"out_result_refi*0\"\n",
    "    params.show_field = \"Q\"\n",
    "    params.warp_field_scalar = \"\"\n",
    "    # params.warp_factor = 0.4  # warp factor\n",
    "    params.show_edges = True\n",
    "    # params.p_save = \"run_test_q.pdf\"\n",
    "    show_results(params)\n",
    "    params.show_field = \"G\"\n",
    "    show_results(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_test and jumps:\n",
    "    params.show_file = \"out_error\"\n",
    "    params.show_field = \"JUMP_L2\"\n",
    "    params.show_edges = True\n",
    "    # params.p_cmap = \"jet\"\n",
    "    # params.p_save = \"c3_err_ind_jump.pdf\"\n",
    "    show_results(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_test:\n",
    "    params.show_file = \"out_error\"\n",
    "    params.show_field = \"ERROR_ESTIMATOR\"\n",
    "    params.show_edges = True\n",
    "    # params.p_cmap = \"jet\"\n",
    "    # params.p_save = \"c3_err_est.pdf\"\n",
    "    show_results(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_test:\n",
    "    params.show_file = \"out_error\"\n",
    "    params.show_field = \"ERROR_INDICATOR_DIV\"\n",
    "    params.show_edges = True\n",
    "    params.warp_field_scalar = \"\"\n",
    "    # params.warp_factor = 0.4  # warp factor\n",
    "    # params.p_save = \"run_test_err_ind_div.pdf\"\n",
    "    show_results(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_test:\n",
    "    params.show_file = \"out_error_0\"\n",
    "    params.show_field = \"ERROR_INDICATOR_GRAD\"\n",
    "    params.show_edges = True\n",
    "    params.warp_field_scalar = \"\"\n",
    "    # params.warp_factor = 0.4  # warp factor\n",
    "    # params.p_save = \"run_test_err_ind_grad.pdf\"\n",
    "    show_results(params)\n",
    "    params.show_file = \"out_error\"\n",
    "    show_results(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison between standard and mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_analysis:    \n",
    "    for i in range(len(ana_compare_name)):\n",
    "        !rm {ana_compare_sum[i]}\n",
    "        !rm ./out_*\n",
    "        for i in range(len(params.element_sizes)):\n",
    "            # params.element_size = elem_size\n",
    "            # params.show_mesh = False\n",
    "            # generate_mesh(params)\n",
    "            # params.part_file = params.mesh_file + \"_\" + str(params.nproc) + \"p.h5m\"\n",
    "            params.part_file = input_names[i]\n",
    "            # !{mofem_part} -my_file {params.mesh_file + \".h5m\"} -my_nparts {params.nproc} -output_file {params.part_file} -dim 2 -adj_dim 1\n",
    "            for order in order_list:\n",
    "                params.order = order\n",
    "                # !mpirun -np {params.nproc} {ana_compare_exe[i]} -file_name {params.part_file} -my_order {params.order} {analytical_solution_tag} {jumps}\n",
    "                !mpirun -np {params.nproc} {exe} -file_name {params.part_file} -my_order {params.order} {analytical_solution_tag} {jumps} -csv_tree_file {params.csv_tree_file}\n",
    "        !mv {sumanalys} ana_DD_mixed.csv\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exe = hdiv_diffusion\n",
    "sumanalys = \"sumanalys.csv\"\n",
    "ana_ref_ord_name = \"ana_L_mixed_order\"\n",
    "\n",
    "refinement_style = 1\n",
    "ref_iter_num = 4\n",
    "ref_control = 1.0\n",
    "params.nproc = 1\n",
    "\n",
    "if run_refinement_analysis:    \n",
    "    !rm {sumanalys}\n",
    "    !rm ./out_*\n",
    "    params.part_file = input_names[input_number]\n",
    "    order = order_list[1]\n",
    "    \n",
    "    # params.element_size = elem_size\n",
    "    # params.show_mesh = True\n",
    "    # generate_mesh(params)\n",
    "    # params.part_file = params.mesh_file + \"_\" + str(params.nproc) + \"p.h5m\"\n",
    "    # !{mofem_part} -my_file {params.mesh_file + \".h5m\"} -my_nparts {params.nproc} -output_file {params.part_file} -dim 2 -adj_dim 1\n",
    "    # params.part_file= input_names[1]\n",
    "    params.order = order\n",
    "    !mpirun -np {params.nproc} {exe} -file_name {params.part_file} -my_order {params.order} {analytical_solution_tag} -refinement_style {refinement_style} -ref_iter_num {ref_iter_num} -ref_control {ref_control} {jumps}\n",
    "    !mv {sumanalys} {ana_ref_ord_name}.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!convert.py out*\n",
    "\n",
    "if run_refinement_analysis:\n",
    "    params.show_file = \"out_error\"\n",
    "    params.show_field = \"ORDER\"\n",
    "    params.show_edges = True\n",
    "    # params.p_cmap = \"rainbow\"\n",
    "    # params.p_save = \"run_test_err_ind_grad.pdf\"\n",
    "    show_results(params)\n",
    "\n",
    "    params.show_file = \"out_error\"\n",
    "    params.show_field = \"ERROR_INDICATOR_GRAD\"\n",
    "    params.show_edges = True\n",
    "    # params.p_cmap = \"jet\"\n",
    "    # params.p_save = \"run_test_err_ind_grad.pdf\"\n",
    "    show_results(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mesh refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exe = hdiv_diffusion\n",
    "sumanalys = \"sumanalys.csv\"\n",
    "ana_ref_mesh_name = \"ana_L_mixed_mesh\"\n",
    "\n",
    "if run_refinement_mesh_analysis:   \n",
    "    refinement_style = 2\n",
    "    ref_iter_num = 4\n",
    "    ref_control = 1.0\n",
    "    params.nproc = 1\n",
    "\n",
    "    !rm {sumanalys}\n",
    "    !rm ./out_*\n",
    "    order = order_list[1]\n",
    "    params.part_file = input_names[input_number]\n",
    "\n",
    "    # params.element_size = elem_size\n",
    "    # params.show_mesh = True\n",
    "    # generate_mesh(params)\n",
    "    # params.part_file = params.mesh_file + \"_\" + str(params.nproc) + \"p.h5m\"\n",
    "    # !{mofem_part} -my_file {params.mesh_file + \".h5m\"} -my_nparts {params.nproc} -output_file {params.part_file} -dim 2 -adj_dim 1\n",
    "    \n",
    "    params.order = order\n",
    "    !mpirun -np {params.nproc} {exe} -file_name {params.part_file} -my_order {params.order} {analytical_solution_tag} -refinement_style {refinement_style} -ref_iter_num {ref_iter_num} -ref_control {ref_control} {jumps}\n",
    "    !mv {sumanalys} {ana_ref_mesh_name}.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!convert.py out*\n",
    "\n",
    "if run_refinement_mesh_analysis:\n",
    "    params.show_file = \"out_error\"\n",
    "    params.show_field = \"ERROR_INDICATOR_GRAD\"\n",
    "    params.show_edges = True\n",
    "    # params.p_cmap = \"jet\"\n",
    "    # params.p_save = \"run_test_err_ind_grad.pdf\"\n",
    "    show_results(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_refinement_mesh_analysis:\n",
    "    params.show_file = \"out_error\"\n",
    "    params.show_field = \"ORDER\"\n",
    "    params.show_edges = True\n",
    "    # params.p_cmap = \"jet\"\n",
    "    # params.p_save = \"run_test_err_ind_grad.pdf\"\n",
    "    show_results(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hp refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exe = hdiv_diffusion\n",
    "sumanalys = \"sumanalys.csv\"\n",
    "ana_ref_hp_name = \"ana_L_mixed_hp\"\n",
    "\n",
    "if run_refinement_hp_analysis:   \n",
    "    refinement_style = 3\n",
    "    ref_iter_num = 4\n",
    "    ref_control = 1.0\n",
    "    params.nproc = 1\n",
    "\n",
    "    !rm {sumanalys}\n",
    "    !rm ./out_*\n",
    "    order = order_list[1]\n",
    "    params.part_file= input_names[input_number]\n",
    "\n",
    "    # params.element_size = elem_size\n",
    "    # params.show_mesh = True\n",
    "    # generate_mesh(params)\n",
    "    # params.part_file = params.mesh_file + \"_\" + str(params.nproc) + \"p.h5m\"\n",
    "    # !{mofem_part} -my_file {params.mesh_file + \".h5m\"} -my_nparts {params.nproc} -output_file {params.part_file} -dim 2 -adj_dim 1\n",
    "    \n",
    "    \n",
    "    params.order = order\n",
    "    !mpirun -np {params.nproc} {exe} -file_name {params.part_file} -my_order {params.order} {analytical_solution_tag} -refinement_style {refinement_style} -ref_iter_num {ref_iter_num} -ref_control {ref_control} {jumps} {monte}\n",
    "    !mv {sumanalys} {ana_ref_hp_name}.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!convert.py out*\n",
    "\n",
    "if run_refinement_hp_analysis:\n",
    "    params.show_file = \"out_error\"\n",
    "    params.show_field = \"ORDER\"\n",
    "    params.show_edges = True\n",
    "    # params.p_cmap = \"rainbow\"\n",
    "    # params.p_save = \"run_test_err_ind_grad.pdf\"\n",
    "    show_results(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_refinement_hp_analysis:\n",
    "    params.show_file = \"out_error\"\n",
    "    params.show_field = \"ERROR_INDICATOR_GRAD\"\n",
    "    params.show_edges = True\n",
    "    # params.p_cmap = \"jet\"\n",
    "    # params.p_save = \"run_test_err_ind_grad.pdf\"\n",
    "    show_results(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_refinement_hp_analysis:\n",
    "    params.show_file = \"out_error\"\n",
    "    params.show_field = \"ERROR_ESTIMATOR\"\n",
    "    params.show_edges = True\n",
    "    # params.p_save = \"run_test_err_ind_grad.pdf\"\n",
    "    show_results(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_refinement_hp_analysis:\n",
    "    params.show_file = \"out_result\"\n",
    "    params.show_field = \"T\"\n",
    "    params.show_edges = True\n",
    "    # params.p_save = \"run_test_err_ind_grad.pdf\"\n",
    "    show_results(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(naming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_name_list = []\n",
    "error_label_list = []\n",
    "\n",
    "# error_name_list.append(\"L2norm\")\n",
    "# error_label_list.append(r'Global error $L^2$-norm')\n",
    "# error_name_list.append(\"H1seminorm\")\n",
    "# error_label_list.append(r'Global error $H^1$-seminorm')\n",
    "# error_name_list.append(\"fluxErr\")\n",
    "# error_label_list.append(r'Global Flux error')\n",
    "\n",
    "error_name_list.append(\"rmsPoiErr\")\n",
    "error_label_list.append(r'Global error to material dataset')\n",
    "\n",
    "error_name_list.append(\"errorEstimator\")\n",
    "error_label_list.append(r'Global error estimator')\n",
    "error_name_list.append(\"errorIndicatorGrad\")\n",
    "error_label_list.append(r'Global error indicator grad')\n",
    "error_name_list.append(\"errorIndicatorDiv\")\n",
    "error_label_list.append(r'Global error indicator div')\n",
    "\n",
    "if jumps:\n",
    "    error_name_list.append(\"jumpL2\")\n",
    "    error_label_list.append(r'Global jump L2')\n",
    "    # error_name_list.append(\"jumpHdiv\")\n",
    "    # error_label_list.append(r'Global jump Hdiv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_prefix = \"c3_mixed_L_\"\n",
    "\n",
    "mixed_ana = Analysis(\"ana_DD_mixed\", naming, order_list, error_name_list, error_label_list, filename_prefix, elem_size_list,  marker='x', linestyle='--', plot_gradients=True, label=\"Mixed\")\n",
    "# classic_ana = Analysis(ana_compare_name[1], naming, order_list, error_name_list, error_label_list, filename_prefix, elem_size_list,  marker='o', linestyle='-', plot_gradients=False, label=\"Classic\")\n",
    "\n",
    "\n",
    "order_ref_ana = Analysis(ana_ref_ord_name, naming, order_list, error_name_list, error_label_list, filename_prefix, elem_size_list,  marker='^', linestyle=':', plot_gradients=False, label=\"Order Refinement\", color = 'black')\n",
    "\n",
    "mesh_ref_ana = Analysis(ana_ref_mesh_name, naming, order_list, error_name_list, error_label_list, filename_prefix, elem_size_list,  marker='v', linestyle=':', plot_gradients=False, label=\"Mesh Refinement\", color = 'black')\n",
    "\n",
    "hp_ref_ana = Analysis(ana_ref_hp_name, naming, order_list, error_name_list, error_label_list, filename_prefix, elem_size_list,  marker='*', linestyle=':', plot_gradients=False, label=\"HP Refinement\", color = 'red')\n",
    "\n",
    "# ana_ref_ord_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixed_ana.plot_both_analyses_by_elem_size([classic_ana])\n",
    "# mixed_ana.plot_both_analyses_by_elem_size([])\n",
    "# mixed_ana.plot_both_analyses_by_gaussnum([classic_ana], [order_ref_ana, mesh_ref_ana])\n",
    "mixed_ana.plot_both_analyses_by_gaussnum([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_ana.plot_gradients = False\n",
    "mixed_ana.legend_fond_size = 12\n",
    "\n",
    "# mixed_ana.plot_both_analyses_by_gaussnum([classic_ana])\n",
    "# mixed_ana.plot_both_analyses_by_elem_size([classic_ana])\n",
    "\n",
    "# if run_refinement_analysis:\n",
    "#     mixed_ana.filename_prefix = \"c3_mixed_L_ref_order_\"\n",
    "#     mixed_ana.plot_both_analyses_by_gaussnum([], [order_ref_ana])\n",
    "# if run_refinement_mesh_analysis:\n",
    "#     mixed_ana.filename_prefix = \"c3_mixed_L_ref_mesh_\"\n",
    "#     mixed_ana.plot_both_analyses_by_gaussnum([], [mesh_ref_ana])\n",
    "# if run_refinement_analysis and run_refinement_mesh_analysis:\n",
    "mixed_ana.filename_prefix = \"c3_mixed_L_ref_hp_\"\n",
    "mixed_ana.plot_both_analyses_by_gaussnum([], [order_ref_ana, mesh_ref_ana, hp_ref_ana])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./results\n",
    "!mv *.pdf ./results\n",
    "!mv *.svg ./results\n",
    "!mv *.png ./results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import os\n",
    "import gc\n",
    "\n",
    "def create_gif_from_vtk(params):\n",
    "    out_to_vtk = !ls -v {params.show_file}*vtk\n",
    "\n",
    "    print(out_to_vtk)\n",
    "\n",
    "    filenames = []\n",
    "\n",
    "    for i, file in enumerate(out_to_vtk):\n",
    "        p = pv.Plotter(notebook=True)\n",
    "\n",
    "        mesh = pv.read(file)\n",
    "\n",
    "        warped_mesh = mesh\n",
    "\n",
    "        if params.warp_field_scalar:\n",
    "            warped_mesh = mesh.warp_by_scalar(scalars=params.warp_field_scalar, factor=params.warp_factor)\n",
    "        \n",
    "        if params.warp_field_vector:\n",
    "            warped_mesh = mesh.warp_by_vector(vectors=params.warp_field_vector, factor=params.warp_factor)\n",
    "\n",
    "        if params.show_edges:\n",
    "            warped_mesh=warped_mesh.shrink(0.95)\n",
    "\n",
    "        if params.show_field in warped_mesh.point_data:\n",
    "            data_location = warped_mesh.point_data\n",
    "        elif params.show_field in warped_mesh.cell_data:\n",
    "            data_location = warped_mesh.cell_data\n",
    "        else:\n",
    "            raise KeyError(f\"Field '{params.show_field}' not found in point or cell data.\")\n",
    "\n",
    "        if (params.field_part < 0):\n",
    "            scalars = data_location[params.show_field]\n",
    "        elif params.field_part == 10: # plot gradient\n",
    "            warped_mesh = warped_mesh.compute_derivative(scalars=params.show_field, preference='point')\n",
    "            scalars = warped_mesh.point_data['gradient']\n",
    "        else:\n",
    "            scalars = warped_mesh.point_data[params.show_field][:,params.field_part]\n",
    "\n",
    "        if params.show_ori_shape:\n",
    "            p.add_mesh(mesh, component=None, smooth_shading=True, opacity=0.5, color='gray')\n",
    "\n",
    "             # Define the arguments for the scalar bar\n",
    "        scalar_bar_args = {\n",
    "            # 'n_labels': 8,\n",
    "            'position_x': 0.2,  \n",
    "        }\n",
    "\n",
    "        p.add_mesh(warped_mesh, scalars=scalars, component=None, smooth_shading=False, cmap=params.p_cmap, clim = params.clim, show_scalar_bar=params.show_scalar_bar, opacity=0.9, scalar_bar_args=scalar_bar_args)\n",
    "    \n",
    "        p.camera_position = params.camera_position\n",
    "        \n",
    "        p.enable_parallel_projection()\n",
    "        p.enable_image_style()\n",
    "        \n",
    "        # Save the plot as an image with reduced resolution\n",
    "        filename = f\"frame_{i}.png\"\n",
    "        p.screenshot(filename, window_size=[800, 600])  # Adjust the window size as needed\n",
    "\n",
    "        # Close the plotter\n",
    "        p.close()\n",
    "\n",
    "        # Append the filename to the list\n",
    "        filenames.append(filename)\n",
    "\n",
    "        # Delete large variables and collect garbage\n",
    "        del mesh, warped_mesh, scalars\n",
    "        gc.collect()\n",
    "\n",
    "    # Create a gif from the image files with a 0.2 second delay between frames\n",
    "    with imageio.get_writer(params.gif_name+'.gif', mode='I', duration=1) as writer:\n",
    "        for filename in filenames:\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)\n",
    "\n",
    "    # with imageio.get_writer(params.gif_name+'.mp4', fps=2) as writer:\n",
    "    #     for filename in filenames:\n",
    "    #         image = imageio.imread(filename)\n",
    "    #         writer.append_data(image)\n",
    "            \n",
    "    # Optionally, delete the individual frame images\n",
    "    for filename in filenames:\n",
    "        os.remove(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start display for showing results\n",
    "display = Display(backend=\"xvfb\", visible=False, size=(1024, 768))\n",
    "display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.show_file = \"out_sigma_ele\"\n",
    "params.show_field = \"SIGMA_FLUX_Y\"\n",
    "params.show_edges = False\n",
    "params.p_cmap = \"rainbow\"\n",
    "params.p_cmap = \"viridis\"\n",
    "params.gif_name = \"gif_sigma_q_y\"\n",
    "# params.p_save = \"run_test_err_ind_grad.pdf\"\n",
    "print(\"0\")\n",
    "create_gif_from_vtk(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.show_file = \"out_before_\"\n",
    "params.show_field = \"Q\"\n",
    "params.field_part = 1\n",
    "params.show_edges = False\n",
    "params.p_cmap = \"rainbow\"\n",
    "params.p_cmap = \"inferno\"\n",
    "params.gif_name = \"gif_q_y\"\n",
    "# params.clim = [-10, 30]\n",
    "# params.p_save = \"run_test_err_ind_grad.pdf\"\n",
    "print(\"0\")\n",
    "create_gif_from_vtk(params)\n",
    "params.field_part = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if run_test:\n",
    "params.show_file = \"out_error\"\n",
    "params.show_field = \"ERROR_ESTIMATOR\"\n",
    "params.show_edges = True\n",
    "# params.p_cmap = \"jet\"\n",
    "params.p_save = \"ECCOMAS_error_est.pdf\"\n",
    "show_results(params)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
